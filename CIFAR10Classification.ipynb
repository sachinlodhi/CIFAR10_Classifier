{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TsgYhBfhOWn"
      },
      "source": [
        "import sys\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZWaKu4Xipjq"
      },
      "source": [
        "def load_dataset():\n",
        "    # loading of the data\n",
        "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "    print(f'Train : X = {trainX.shape}, Y = {trainY}')\n",
        "    print(f'Test : X = {testX.shape}, Y = {testY}')\n",
        "\n",
        "    # one hot encoding for categorical data (only output)\n",
        "\n",
        "    trainY = keras.utils.to_categorical(trainY)\n",
        "    testY = keras.utils.to_categorical(testY)\n",
        "    return trainX, trainY, testX, testY"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrO_WLJziu7Y"
      },
      "source": [
        "def prep_pixels(train, test):\n",
        "    train_norm = train.astype('float32')\n",
        "    test_norm  = test.astype('float32')\n",
        "\n",
        "    # normalize between 0-1\n",
        "    train_norm = train_norm / 255.0\n",
        "    test_norm = test_norm / 255.0\n",
        "\n",
        "    # returning scaled images or normalized images\n",
        "    return train_norm, test_norm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH0U_m_mi4Vo"
      },
      "source": [
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFHhlfJ5i7Tg"
      },
      "source": [
        "def summarize_diagnostics(history):\n",
        "    # plot the loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title(\"Cross Entropy Loss\")\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwfSecRojBPS"
      },
      "source": [
        "def run_test():\n",
        "    # load dataset\n",
        "    trainX, trainY, testX, testY = load_dataset()\n",
        "    # prepare pixel data\n",
        "    trainX, testX = prep_pixels(trainX, testX)\n",
        "    # define model\n",
        "    model = define_model()\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY, epochs=20, batch_size=64, validation_data=(testX, testY), verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "\n",
        "    #learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    model.save(\"cifar_model_10.h5\")\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzg-XGsCjDFU",
        "outputId": "921e8a8f-9508-41a2-ac76-c71b3d0eb194"
      },
      "source": [
        "run_test()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train : X = (50000, 32, 32, 3), Y = [[6]\n",
            " [9]\n",
            " [9]\n",
            " ...\n",
            " [9]\n",
            " [1]\n",
            " [1]]\n",
            "Test : X = (10000, 32, 32, 3), Y = [[3]\n",
            " [8]\n",
            " [8]\n",
            " ...\n",
            " [5]\n",
            " [1]\n",
            " [7]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.7536 - accuracy: 0.3646 - val_loss: 1.4825 - val_accuracy: 0.4586\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3980 - accuracy: 0.4970 - val_loss: 1.3059 - val_accuracy: 0.5316\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2146 - accuracy: 0.5672 - val_loss: 1.2107 - val_accuracy: 0.5586\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0817 - accuracy: 0.6183 - val_loss: 1.1112 - val_accuracy: 0.6054\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9790 - accuracy: 0.6560 - val_loss: 0.9962 - val_accuracy: 0.6474\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8912 - accuracy: 0.6880 - val_loss: 0.9493 - val_accuracy: 0.6680\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8203 - accuracy: 0.7145 - val_loss: 0.9434 - val_accuracy: 0.6719\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7625 - accuracy: 0.7343 - val_loss: 0.8571 - val_accuracy: 0.7015\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6969 - accuracy: 0.7569 - val_loss: 0.8426 - val_accuracy: 0.7050\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.6525 - accuracy: 0.7736 - val_loss: 0.8156 - val_accuracy: 0.7163\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5962 - accuracy: 0.7940 - val_loss: 0.8432 - val_accuracy: 0.7095\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5527 - accuracy: 0.8077 - val_loss: 0.8695 - val_accuracy: 0.7111\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5134 - accuracy: 0.8199 - val_loss: 0.8789 - val_accuracy: 0.7129\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4663 - accuracy: 0.8374 - val_loss: 0.8414 - val_accuracy: 0.7216\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4222 - accuracy: 0.8526 - val_loss: 0.8780 - val_accuracy: 0.7206\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3804 - accuracy: 0.8666 - val_loss: 0.9538 - val_accuracy: 0.7057\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3437 - accuracy: 0.8797 - val_loss: 0.9719 - val_accuracy: 0.7144\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3045 - accuracy: 0.8940 - val_loss: 0.9455 - val_accuracy: 0.7248\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2692 - accuracy: 0.9047 - val_loss: 0.9933 - val_accuracy: 0.7215\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2279 - accuracy: 0.9202 - val_loss: 1.0400 - val_accuracy: 0.7270\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.0400 - accuracy: 0.7270\n",
            "> 72.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZcq5I0IwK_H"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLjovgqbwute"
      },
      "source": [
        "def load_image(filename):\n",
        "\n",
        "  img = load_img(filename, target_size =(32,32))\n",
        "  img = img_to_array(img)\n",
        "  img = img.reshape(1,32,32,3)\n",
        "  img = img.astype(\"float32\")\n",
        "  img = img / 255.0\n",
        "  return img"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100OR2CcxH32"
      },
      "source": [
        "def run_example():\n",
        "\n",
        "  img = load_image(\"/content/deer.jpg\")\n",
        "  model = load_model(\"/content/cifar_model_10.h5\")\n",
        "  result = model.predict_classes(img)\n",
        "  cifar_list =['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog',\n",
        "               'frog', 'horse', 'ship', 'truck']\n",
        "  index = result[0]\n",
        "  print(cifar_list[index])\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1N20NZax559",
        "outputId": "823daca8-f1cd-44c5-c58f-b0f21166dfe1"
      },
      "source": [
        "run_example()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}